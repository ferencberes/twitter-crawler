{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, sys, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,\"../../python/\")\n",
    "import rg17.text_cleaning as tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load stemmed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmed_tweets = pd.read_csv(\"/mnt/idms/fberes/network/roland_garros/data/rg17_tweets_eng_stemmed.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmed_tweets = stemmed_tweets[[\"time\",\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert epoch to GMT time (D\u00e1vid uses this format for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmed_tweets[\"gmt_time\"] = stemmed_tweets[\"time\"].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snapshot_hours = [1,4,7,10,13,16,19,22]\n",
    "\n",
    "def round_hour_value(hour_val):\n",
    "    if hour_val % 3 == 2:\n",
    "        return hour_val - 1\n",
    "    elif hour_val % 3 == 0:\n",
    "        return hour_val - 2\n",
    "    else:\n",
    "        return hour_val\n",
    "\n",
    "def get_snapshot_id(gmt_time):\n",
    "    date_rec, time_rec = gmt_time.split()\n",
    "    hour_value = int(time_rec.split(\":\")[0])\n",
    "    rounded_hour = round_hour_value(hour_value)\n",
    "    if rounded_hour == -2:\n",
    "        rounded_hour = 22\n",
    "        dt = datetime.datetime.strptime(date_rec, \"%Y-%m-%d\")\n",
    "        dt_new = dt - datetime.timedelta(days=1)\n",
    "        date_rec = \"%.4i-%.2i-%.2i\" % (dt_new.year, dt_new.month, dt_new.day)\n",
    "    return \"%sT%.2i:00\" % (date_rec, rounded_hour)\n",
    "    \n",
    "print(get_snapshot_id(\"2017-06-11 21:00:59\"))\n",
    "print(get_snapshot_id(\"2017-06-11 00:00:59\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmed_tweets[\"snapshot_id\"] = stemmed_tweets[\"gmt_time\"].apply(get_snapshot_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmed_tweets[\"date\"] = stemmed_tweets[\"snapshot_id\"].apply(lambda x: x.split(\"T\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for evaluation timeframes (June 6 - June 11) - for faster preprocessing before W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(stemmed_tweets))\n",
    "stemmed_tweets = stemmed_tweets[(stemmed_tweets[\"date\"] >= \"2017-06-05\") & (stemmed_tweets[\"date\"] <= \"2017-06-12\")] # rather from 06-05\n",
    "print(len(stemmed_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load selected word corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_words = []\n",
    "with open(\"/mnt/idms/fberes/network/roland_garros/data/rg17_8000_important_en_words_plus_players.txt\") as f:\n",
    "    for line in f:\n",
    "        selected_words.append(line.rstrip())\n",
    "selected_words = set(selected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(selected_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Filter tweet texts for relevant words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) Cleaning based on regexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmed_tweets[\"cleaned_text\"] = stemmed_tweets[\"text\"].apply(tc.clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) Cleaning based on word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmed_tweets[\"word_list\"] = stemmed_tweets[\"cleaned_text\"].apply(lambda x: tc.get_words_above_size_limit(x,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c.) Leaving only the selected words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmed_tweets[\"selected_word_list\"] = stemmed_tweets[\"word_list\"].apply(lambda x: list(set(x).intersection(selected_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training Word2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_w2v_model(snapshot_id, dump_model=False):\n",
    "    partial_df = stemmed_tweets[stemmed_tweets[\"snapshot_id\"] == snapshot_id]\n",
    "    # dropping tweets with only one word - no use for w2v\n",
    "    partial_df = partial_df[partial_df[\"selected_word_list\"].apply(lambda x: True if len(x) > 2 else False)]\n",
    "    print(\"Number of tweets for training: %i\" % len(partial_df))\n",
    "    w2v_data = list(partial_df[\"selected_word_list\"])\n",
    "    model = gensim.models.Word2Vec(w2v_data, min_count=5)\n",
    "    if dump_model:\n",
    "        model.save(fname_or_handle=\"/mnt/idms/fberes/network/roland_garros/models/%s.w2v\" % snapshot_id)\n",
    "    return (snapshot_id, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training + Exporting models for all snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snapshot_ids = list(stemmed_tweets[\"snapshot_id\"].unique())\n",
    "for snapshot_id in sorted(snapshot_ids):\n",
    "    snapshot_id, _ = train_w2v_model(snapshot_id, dump_model=True)\n",
    "    print(snapshot_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "snapshot_ids = [\"2017-06-11T10:00\", \"2017-06-11T13:00\", \"2017-06-11T16:00\"]\n",
    "w2v_models = []\n",
    "for snapshot_id in snapshot_ids:\n",
    "    w2v_models.append(train_w2v_model(snapshot_id, dump_model=False))\n",
    "w2v_models = dict(w2v_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}